# A. index

1. 확률론 (언어): 불확실성을 수학적으로 표현하는 언어를 배웁니다.
    - 분포
2. 기술통계 (관찰): 주어진 데이터를 요약하고 특징을 파악합니다.
3. 추론통계 (추론): 관찰한 데이터를 바탕으로 보이지 않는 전체(모집단)에 대해 결론을 내립니다.
4. 추론의 관점들: 추론을 하는 두 가지 큰 사상(빈도주의 vs 베이즈주의)을 비교합니다.
    1. 빈도주의
    2. **베이즈주의**
5. 통계 모델링 (예측과 설명): 데이터 안의 관계를 함수로 규명하고 미래를 예측합니다.
    1. regression
    2. ANOVA
    3. 차원축소 (ex. PCA)
    4. 시계열 분석 
6. 계산통계 (현대적 도구): 컴퓨터의 힘을 빌려 고전적인 방법의 한계를 극복합니다.


# B. prerequisites for deep learning 

## 1순위
이 지식들은 딥러닝 모델의 구조와 학습 과정을 이해하는 데 있어 '알파벳'과도 같습니다.

1. 확률론 (언어): 가장 중요합니다.
    - 왜?: 현대 딥러닝은 근본적으로 '확률 모델링'입니다.
    - 활용처:
        - 손실 함수: 분류 문제에서 사용하는 **크로스 엔트로피(Cross-Entropy)** 는 정보 이론과 확률 분포 간의 거리에서 나온 개념입니다.
        - 활성화 함수: 출력층의 소프트맥스(Softmax) 함수는 각 클래스에 대한 확률을 계산해 줍니다.
        - 생성 모델: VAE, GAN, Diffusion과 같은 최신 생성 모델들은 모두 확률 분포를 학습하고 여기서부터 새로운 데이터를 샘플링하는 원리입니다.
    - 특히 확률 분포: 베르누이/카테고리 분포(분류 문제), 정규 분포(가중치 초기화, 노이즈 모델링, VAE), 균등 분포(초기화) 등은 반드시 알아야 합니다.
2. 기술통계 (관찰): 가장 먼저 해야 할 일입니다.
    - 왜?: "Garbage in, garbage out." 데이터에 대한 이해 없이 모델을 만들 수는 없습니다.
    - 활용처:
        - 데이터 전처리(EDA): 모델에 데이터를 넣기 전, 데이터의 평균, 표준편차, 분포 등을 파악하여 인사이트를 얻고 문제를 정의합니다.
        - 정규화(Normalization/Standardization): 데이터의 스케일을 조정하여 모델 학습을 안정시키고 속도를 높이는 데 필수적입니다.
        - 이상치 탐지: 모델의 학습을 방해하는 이상한 데이터들을 찾아내고 처리하는 데 사용됩니다.
3. 통계 모델링 중 회귀분석(Regression): 머신러닝의 "Hello, World!"입니다.
    - 왜?: 딥러닝은 매우 복잡하고 비선형적인 회귀/분류 모델일 뿐입니다. 가장 간단한 **선형 회귀(Linear Regression)** 를 이해하는 것이 모든 예측 모델링의 출발점입니다.
    - 활용처: 손실 함수(MSE), 예측 모델의 기본 구조, 변수 간의 관계를 수식으로 표현하는 아이디어 등 모든 것이 여기서 시작됩니다.



## 2순위
이 지식들은 모델의 작동 방식을 더 깊이 이해하고, 왜 특정 기법들이 효과적인지에 대한 통찰을 줍니다.

5. 추론의 관점들 (철학): 딥러닝의 학습 원리를 설명합니다.
    - 빈도주의 (특히 MLE): **최대가능도추정(Maximum Likelihood Estimation)** 은 "현재 데이터가 나올 가능도를 최대로 만드는 파라미터를 찾아라"는 원리입니다. MSE나 크로스 엔트로피 같은 손실 함수를 최소화하는 것은, 특정 확률 분포 가정 하에서 MLE를 수행하는 것과 수학적으로 동일합니다. 왜 우리가 그 손실 함수를 쓰는지에 대한 근본적인 답을 줍니다.
    - 베이즈주의: 모델 파라미터를 '확률 분포'로 간주하는 접근법입니다. **드롭아웃(Dropout)** 과 같은 정규화 기법의 이론적 배경을 설명해 주며, 모델의 불확실성 측정(Uncertainty Estimation), 베이지안 신경망(BNN) 등 고급 주제로 나아가는 데 필수적입니다.
4. 통계 모델링 중 차원 축소(PCA): 데이터 표현(Representation)에 대한 직관을 줍니다.
    - 왜?: PCA는 데이터의 가장 중요한 '정보의 축'을 찾는 방법입니다.
    - 활용처: 딥러닝의 **오토인코더(Autoencoder)** 가 데이터를 저차원의 잠재 공간(latent space)으로 압축하는 원리와 매우 유사합니다. 데이터의 본질적인 구조를 어떻게 효율적으로 표현할지에 대한 중요한 직관을 제공합니다.
6. 계산통계 (현대적 도구): 딥러닝의 학습 트릭들을 이해하게 합니다.
    - 왜?: 딥러닝은 컴퓨터의 계산 능력을 적극적으로 활용하는 분야입니다.
    - 활용처: 몬테카를로 방법의 아이디어는 드롭아웃이나 앙상블 기법과 연결됩니다. 데이터셋의 일부(미니배치)만 무작위로 뽑아 학습하는 **확률적 경사 하강법(SGD)** 은 계산통계의 핵심 아이디어에 기반합니다.

