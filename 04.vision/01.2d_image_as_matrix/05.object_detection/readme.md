# A. what 
- feature extract는 이 이미지 안에 어떤 특징들이 있지? 라면,
- object detection은 이거에 더 얹어서, 그 특징이 정확히 어딨지? 까지 커버함 

## a. goal 
- Bounding Box: 객체의 위치를 감싸는 사각형의 좌표 (x, y, 너비, 높이)
- Class Label: 그 상자 안에 있는 객체가 무엇인지 (고양이, 자동차 등)
- Confidence Score: 모델이 자신의 예측을 얼마나 확신하는지 (예: 98%)

## b. history 
### b-1. sliding window 
가장 원시적이고 직관적인 방법입니다. "돋보기로 그림 전체를 샅샅이 훑는" 방식과 같습니다.

1. 탐색 상자(Window) 준비: 다양한 크기와 비율의 사각형 상자들을 미리 여러 개 정의합니다. (예: 길쭉한 상자, 정사각형 상자, 큰 상자, 작은 상자)
2. 전체 이미지 스캔: 준비한 상자 하나를 들고, 이미지 왼쪽 위부터 오른쪽 아래까지 한 칸씩 이동하며 샅샅이 훑습니다.
3. 분류 (Classification): 상자가 멈출 때마다 그 안의 이미지 조각을 잘라내서, 우리가 잘 아는 이미지 분류 CNN 모델에 넣고 "이 안에 고양이가 있니?"라고 물어봅니다.
4. 위치 기록: 모델이 "네, 95% 확률로 고양이입니다!"라고 대답하면, 해당 상자의 위치를 기록합니다.
5. 반복: 모든 종류의 상자로 이 과정을 무한 반복합니다.

- 장점: 원리가 매우 간단하고, 놓치는 영역 없이 모든 곳을 확인할 수 있습니다.
- 치명적인 단점: 느려 터졌습니다. 이미지 한 장을 분석하기 위해 수천, 수만 번의 분류를 해야 하므로 사실상 실용성이 거의 없습니다.

### b-2. two-stage detector (R-CNN)
"무식하게 다 보지 말고, **'객체가 있을 법한 후보 영역'** 만 먼저 찾아서 거기만 집중적으로 보자!"라는 아이디어에서 출발했습니다. R-CNN 계열 모델들이 여기에 해당합니다.

#### R-CNN (최초의 혁신)
- 후보 영역 제안 (Region Proposal): 'Selective Search' 같은 알고리즘을 사용해, 이미지에서 객체가 있을 만한 그럴싸한 영역(Region of Interest, RoI)을 약 2000개 정도 미리 뽑아냅니다.
- 특징 추출 및 분류: 2000개의 후보 영역 각각을 CNN 분류기에 넣어 객체인지 아닌지, 객체라면 무엇인지 분류합니다. (여전히 2000번의 CNN 연산이 필요해서 느립니다.)


#### Faster R-CNN (2세대 방식의 완성형)
R-CNN의 느린 속도를 개선하다가 마침내 완성된 형태입니다. 현대 객체 탐지 기술의 근간이 되는 매우 중요한 모델입니다.

1. 특징 추출 (딱 한 번만!): 일단 이미지 전체를 통째로 거대한 CNN(특징 추출기)에 딱 한 번만 넣습니다. 이를 통해 이미지 전체에 대한 풍부한 정보가 담긴 '종합 특징 맵(Feature Map)'을 만듭니다. (이전 슬라이딩 윈도우나 R-CNN에 비해 엄청난 효율 향상!)
2. 후보 영역 제안 네트워크 (Region Proposal Network, RPN): 이제 별도의 알고리즘 대신, 1단계에서 만든 **'종합 특징 맵' 위에서 작동하는 작은 신경망(RPN)**이 "이 특징 맵을 보니, 대략 이쯤에 객체가 있을 것 같네요"라며 후보 영역(RoI)들을 수백 개 제안합니다. 모든 과정이 GPU 위에서 돌아가는 완전한 딥러닝 파이프라인이 완성된 것입니다.
3. 분류 및 위치 보정: RPN이 제안한 후보 영역들만 가져와서, 각 영역이 어떤 객체인지 최종적으로 분류하고, 바운딩 박스의 위치를 좀 더 정밀하게 보정합니다.

- 장점: 정확도가 매우 높습니다.
- 단점: '후보 영역 제안'과 '최종 분류'라는 2단계를 거치기 때문에, 아래 설명할 1단계 탐지기보다는 상대적으로 속도가 느립니다.


### b-3. one-stage detector (YOLO)
"후보 영역 제안 같은 거추장스러운 거 다 빼고, 그냥 한 번에 위치랑 종류를 다 예측해버리자!"라는 과감한 아이디어에서 출발했습니다. YOLO(You Only Look Once) 와 SSD가 대표적 

YOLO (You Only Look Once)
1. 그리드 분할: 이미지를 바둑판처럼 7x7 또는 13x13 같은 그리드(Grid)로 나눕니다.
2. 동시 예측: 이미지를 거대한 CNN에 딱 한 번 통과시켜, 그리드의 각 셀(Cell)마다 다음 정보들을 한꺼번에 예측하도록 합니다.
    - 이 셀 안에 객체가 있을 확률 (Confidence Score)
    - 이 셀을 기준으로 하는 바운딩 박스의 좌표 (x, y, w, h)
    - 이 셀에 있는 객체가 각 클래스(고양이, 개, 자동차...)일 확률
3. 결과 정리: 수많은 예측 결과 중에서 신뢰도가 낮은 것들은 버리고, 중복된 박스들은 합치는 후처리(Non-Maximum Suppression, NMS)를 통해 최종 결과를 얻습니다.

- 장점: 매우 빠릅니다. 후보 영역을 찾는 단계가 없어서 실시간 영상 처리도 가능할 정도입니다.
- 단점: 2단계 방식보다 정확도(특히 작은 객체에 대한)가 약간 떨어지는 경향이 있습니다.

