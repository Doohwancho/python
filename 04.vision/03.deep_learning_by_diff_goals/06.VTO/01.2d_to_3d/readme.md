1. 근본 모델 (Foundational Models, ~2017-2020)

이 시기의 모델들은 VTO를 2D 이미지 위에서 해결하려는 접근을 주로 사용했습니다. 대표적인 모델로 CP-VTON, VITON 등이 있습니다. 이들의 파이프라인은 보통 다음과 같은 3단계 구조를 가집니다.

1단계: 입력 분석 모듈 (Human Parser & Pose Estimator)
- 역할: 사람의 자세와 신체 부위를 분석합니다.
- 사용 기술:
    - Human Parser: 이미지의 각 픽셀이 어떤 신체 부위(얼굴, 머리카락, 상의, 하의, 팔, 다리 등)에 속하는지 분할(Segmentation)합니다. U-Net과 같은 Segmentation 모델이 주로 사용됩니다.
    - Pose Estimator: 사람의 어깨, 팔꿈치, 손목 등 주요 관절의 2D 위치(Keypoints)를 찾아냅니다. OpenPose 같은 기술이 여기에 해당합니다.
- 결과물: 사람의 자세를 나타내는 '뼈대(Skeleton)'와, 신체 부위별로 색칠된 '분할 마스크(Segmentation Map)'.


2단계: 옷 변형 모듈 (Geometric Warping Module)
- 역할: 1단계에서 얻은 '뼈대'와 '분할 마스크' 정보를 이용해, 평평한 옷 이미지를 사람의 상체 모양에 맞게 기하학적으로 구부립니다.
- 사용 기술:
    - Thin Plate Spline (TPS) Transformation: 몇 개의 제어점(Control Point)을 기준으로 이미지를 부드럽게 변형시키는 고전적인 수학적 기법입니다. 딥러닝 네트워크가 옷의 특징점과 사람의 관절점을 매칭시켜주는 최적의 TPS 파라미터를 예측하도록 학습합니다.
    - Flow Field Prediction: TPS보다 더 유연한 방식으로, 옷 이미지의 모든 픽셀이 최종적으로 어디로 이동해야 하는지를 나타내는 '변위 벡터 필드'를 신경망이 직접 예측하기도 합니다.
- 결과물: 사람의 상체 모양처럼 둥글게, 혹은 팔 모양처럼 굽혀진 옷 이미지.

3단계: 이미지 합성 모듈 (Try-on Synthesis Module)

- 역할: 사람 이미지(기존 옷은 지워진), 변형된 옷 이미지, 그리고 보존해야 할 신체 부위(얼굴, 팔 등)를 합쳐 최종 결과물을 생성합니다.
- 사용 기술:
    - Conditional GAN (cGAN): **생성자(Generator)**와 **감별자(Discriminator)**가 경쟁하는 GAN 구조를 사용합니다.
    - 생성자 (Generator): U-Net과 유사한 구조를 가지며, 변형된 옷과 사람 정보를 입력(Condition)으로 받아 "이 조건에 맞는 진짜 같은 이미지를 만들어봐!"라는 미션을 수행합니다. 비어 있는 옷 부분을 자연스럽게 채워 넣는 Inpainting 기술과 유사합니다.
    - 감별자 (Discriminator): 생성자가 만든 이미지가 진짜 사진인지, 아니면 가짜로 만들어낸 이미지인지 판별하며 생성자의 성능을 끌어올립니다.
- 결과물: 사용자가 새로운 옷을 입고 있는 최종 이미지.

