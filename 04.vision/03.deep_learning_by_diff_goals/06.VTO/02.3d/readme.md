
## 2. 최신 SOTA 모델 (State-of-the-Art, ~2021-현재)

근본 모델들은 가능성을 보여줬지만, 옷의 질감이 뭉개지거나, 복잡한 포즈에서 부자연스러워지는 한계가 명확했습니다. 최신 모델들은 이 문제를 해결하기 위해 2D의 한계를 넘어 3D 정보를 활용하고, 더 강력한 생성 모델인 디퓨전(Diffusion)을 도입하는 추세입니다.

대표적인 모델로 LaDI-VTON, StableVITON, 그리고 최근 가장 주목받는 OOTDiffusion 등이 있습니다.

### 핵심적인 발전 방향
1. 3D 정보의 적극적인 활용 (3D-Aware Warping):
    - 2D 키포인트만 사용하는 대신, 딥러닝 모델이 입력된 2D 이미지로부터 사람의 **3D 신체 메시(Mesh)나 UV 맵(3D 모델의 2D 전개도)**을 추정합니다.
    - 평평한 옷 이미지를 이 3D 정보 위에 씌우듯이(Draping) 변형시키므로, 2D 기반의 TPS보다 훨씬 사실적인 주름과 원근감을 표현할 수 있습니다.

2. 생성 모델의 세대 교체 (GAN → Diffusion):
    - GAN은 학습이 불안정하고, 때때로 세밀한 텍스처(로고, 작은 패턴 등)를 제대로 생성하지 못하는 단점이 있었습니다.
    - **디퓨전 모델(Diffusion Model)**은 노이즈를 점진적으로 제거하며 이미지를 생성하는 방식으로, GAN보다 훨씬 안정적이고 고품질의 이미지를 만들어냅니다. DALL-E 2, Stable Diffusion 등이 모두 디퓨전 기반입니다.
    - VTO에서는 디퓨전 모델이 사람, 포즈, 옷 정보를 조건으로 받아, 노이즈 상태에서부터 최종 VTO 결과물까지 매우 사실적인 질감과 명암을 '생성'해냅니다.
3. 디테일 보존 능력 강화 (Detail Preservation):
    - 최신 모델들은 옷의 '스타일(모양)'과 '텍스처(무늬)'를 분리(Disentanglement)하여 다루는 모듈을 도입합니다.
    - 이를 통해 옷을 심하게 변형시켜도 원본 옷의 로고, 프린팅, 원단 질감 등을 잃어버리지 않고 최종 이미지에 선명하게 재현하는 능력이 크게 향상되었습니다.

